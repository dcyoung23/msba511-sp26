{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89c19ff-5a5e-4cac-bd02-4592c4fd6369",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77994db0",
   "metadata": {},
   "source": [
    "### Guided Tutorial\n",
    "\n",
    "For each step, read the explanation, then **run the code cell(s)** right below it.\n",
    "\n",
    "You will practice:\n",
    "- Loading and inspecting data for a classification problem  \n",
    "- Visualizing features to build intuition about possible splits  \n",
    "- Computing **Gini** and **Entropy** (impurity) for a candidate split  \n",
    "- Training and interpreting a **shallow** decision tree vs. a **fully grown** tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411adf34-2d10-4482-97a5-deaa618bd408",
   "metadata": {},
   "source": [
    "#### Import libraries\n",
    "\n",
    "**Run the next 2 cells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce4bf9-e204-4f0f-b7d6-12781f827bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from dmba import plotDecisionTree\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed variable for code reproducibility\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8ec02-5871-4561-bcde-31504aa0814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import local libraries\n",
    "root_dir = Path.cwd().resolve().parents[0]\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "# Visualization functions\n",
    "from src.utils.helpers import *\n",
    "\n",
    "# Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "#%reload_ext autoreload\n",
    "\n",
    "# Always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae48f3-f57d-4379-a35f-243bf11359b0",
   "metadata": {},
   "source": [
    "### Example 1: Lecture\n",
    "\n",
    "**Create a dataframe for the `RidingMowers.csv` data**\n",
    "\n",
    "In the next cell, we load the dataset from a `.csv` file into a pandas DataFrame so we can explore it and model it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea51738-84a1-4934-b6f0-ce7460ba47f5",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the data for the Riding Mowers Example in lecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87e3bd-ffd4-4c81-af37-5ee0e6ff459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mowers_df = pd.read_csv(os.path.join('..','data','RidingMowers.csv'))\n",
    "mowers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2a532-c85f-4efb-ab7a-2a136babf5d2",
   "metadata": {},
   "source": [
    "**Create a scatterplot for Income and Lot Size with Ownership as the Color**\n",
    "\n",
    "\n",
    "Next, we visualize the relationship between **Income** and **Lot Size** and use color to show the class label (**Ownership**). This helps us see whether a simple split might separate the classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7147423-f8f2-4f52-9324-dd6635879875",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the scatter plot used in lecture to visualize the splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da062ed6-d712-4586-b39c-412a28151a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Income',y='Lot_Size',hue='Ownership', data=mowers_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cd2e2-c42b-4931-a3ac-b4e9571c08c6",
   "metadata": {},
   "source": [
    "**Calculate Gini Index for First Split Condition**\n",
    "\n",
    "Now we try a **candidate split** (a threshold on Income). We separate the data into the left/right child nodes and compute impurity for each side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16478002-39e3-4d08-a917-bb872a453181",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the code used for the first split using Gini index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96aacd-52ce-4a48-8f73-52f3828065ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_value = 59.7\n",
    "split_condition = mowers_df['Income'] <= split_value\n",
    "\n",
    "split_true = list(mowers_df['Ownership'][split_condition])\n",
    "split_false = list(mowers_df['Ownership'][~split_condition])\n",
    "\n",
    "print(f\"Left Split: Income <= {split_value}, Gini Index = {gini_index(split_true)[1]:.3f}\")\n",
    "print(f\"Right Split: Income > {split_value}, Gini Index = {gini_index(split_false)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0badb58-cf3a-4596-b429-70efc1a5e4aa",
   "metadata": {},
   "source": [
    "**Calculate Entropy for First Split Condition**\n",
    "\n",
    "Here we compute **entropy** for the left and right child nodes created by the Income split, and print the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30047045-d739-4c5d-b8ac-6bedc1619d7d",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the code used for the first split using Entropy measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb95a75-85d0-4e7a-b88f-4ef639e4841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Left Split: Income <= {split_value}, Entropy = {entropy_loss(split_true)[1]:.3f}\")\n",
    "print(f\"Right Split: Income > {split_value}, Entropy = {entropy_loss(split_false)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b853ea-410b-4a33-959f-7ce15b668234",
   "metadata": {},
   "source": [
    "**Calculate Overall Gini and Entropy for First Split Condition**\n",
    "\n",
    "Finally, we compute the **overall (weighted)** impurity for this split by weighting each child node’s impurity by its share of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c7d71-28af-47aa-99aa-5cbb41f6ec25",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the code used to calculated the combined impurity of the two nodes for both Gini and Entropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cce874-21a0-41ae-8060-12e384c50c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Combined Gini for Income Split on {split_value} is {weighted_impurity(split_true, split_false, mowers_df['Income'], 'gini'):.3f}\")\n",
    "print(f\"Combined Entropy for Income Split on {split_value} is {weighted_impurity(split_true, split_false, mowers_df['Income'], 'entropy'):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b4868-cd57-47d7-bc7b-82e946aa7281",
   "metadata": {},
   "source": [
    "**Create Decision Tree with a Depth of 2**\n",
    "\n",
    "Use Gini for splitting criteria and display impurity value on nodes.\n",
    "\n",
    "\n",
    "Next, we fit a small decision tree with **max_depth=2** (a shallow, interpretable tree) using **Gini** as the split criterion, then visualize it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fff5b-137a-4d62-9dbf-7907edd8899b",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the code used to create the tree after 3 splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd58cd1-2a88-4303-8597-66113b8f249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mowers_X = mowers_df.drop(columns=['Ownership'])\n",
    "mowers_y = mowers_df['Ownership']\n",
    "dt = DecisionTreeClassifier(max_depth=2, criterion='gini', random_state=SEED)\n",
    "dt.fit(mowers_X, mowers_y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plot_tree(dt, \n",
    "          feature_names=mowers_X.columns, \n",
    "          class_names=['Nonowner', 'Owner'], \n",
    "          filled=True, \n",
    "          impurity=True, \n",
    "          ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab2612-951c-4a38-b3de-0af9a7be83f8",
   "metadata": {},
   "source": [
    "**Create Full Decision Tree**\n",
    "\n",
    "Use Gini for splitting criteria and display impurity value on nodes.\n",
    "\n",
    "\n",
    "Lastly, we fit a **fully grown** decision tree (no max depth) to see how the model continues splitting when not constrained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bb7396-b95d-4f3d-a5c3-a110afd22004",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the code used to create the tree after all splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d45a9-3c5c-4b38-b5d3-7a57ec4edb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = DecisionTreeClassifier(max_depth=None, criterion='gini', random_state=SEED)\n",
    "dt2.fit(mowers_X, mowers_y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plot_tree(dt2, \n",
    "          feature_names=mowers_X.columns, \n",
    "          class_names=['Nonowner', 'Owner'], \n",
    "          filled=True, \n",
    "          impurity=True, \n",
    "          ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5dc00-29c4-4a1f-ac91-5d5290386ba5",
   "metadata": {},
   "source": [
    "## Key DecisionTreeClassifier Parameters\n",
    "\n",
    "Below we will discuss **some** of the key parameters for the `DecisionTreeClassifier` that control **how the tree grows**, **how complex it becomes**, and **how splits are chosen**. Check out the [API Reference](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for the full list of parameters.\n",
    "\n",
    "**`criterion`**\n",
    "Determines how the quality of a split is measured.\n",
    "\n",
    "* `\"gini\"` → Uses Gini impurity (default)\n",
    "* `\"entropy\"` → Uses information gain\n",
    "* `\"log_loss\"` → Similar to entropy but based on logistic loss\n",
    "\n",
    "This controls how \"purity\" is defined.\n",
    "\n",
    "**`splitter`**\n",
    "Strategy used to choose splits.\n",
    "\n",
    "* `\"best\"` → Chooses the best split (default)\n",
    "* `\"random\"` → Chooses the best random split\n",
    "\n",
    "`random` can add variability and sometimes reduce overfitting.\n",
    "\n",
    "**`max_depth`**\n",
    "Maximum depth of the tree.\n",
    "\n",
    "* `None` → Grow until pure or minimum samples reached\n",
    "* Integer (e.g., `max_depth=5`)\n",
    "\n",
    "Limits tree complexity where smaller depth = simpler model.\n",
    "\n",
    "**`min_samples_split`**\n",
    "Minimum samples required to split a node.\n",
    "\n",
    "* Integer → exact number (e.g., `10`)\n",
    "* Float → fraction of dataset (e.g., `0.05`)\n",
    "\n",
    "Larger value = fewer splits and can reduce overfitting.\n",
    "\n",
    "**`min_samples_leaf`**\n",
    "Minimum samples required in a leaf node.\n",
    "\n",
    "Prevents leaves with very few observations.\n",
    "\n",
    "**`max_leaf_nodes`**\n",
    "Limits total number of leaf nodes.\n",
    "\n",
    "Controls tree size directly.\n",
    "\n",
    "**`max_features`**\n",
    "Number of features considered at each split.\n",
    "\n",
    "* `None` → All features\n",
    "* `\"sqrt\"` → √(#features)\n",
    "* `\"log2\"` → log₂(#features)\n",
    "* Integer / Float\n",
    "\n",
    "Adds randomness and useful in ensembles such as Random Forest.\n",
    "\n",
    "**`random_state`**\n",
    "Ensures reproducibility.\n",
    "\n",
    "Very important to **always** fix this value for consistent results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e709d-45c0-402b-98c5-57788e957f9e",
   "metadata": {},
   "source": [
    "### Example 2: Lecture\n",
    "\n",
    "**Create a dataframe for the `UniversalBank.csv` data**\n",
    "\n",
    "In the next cell, we load the dataset from a `.csv` file into a pandas DataFrame so we can explore it and model it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6013028-591a-481b-a4a9-a509e4a3df79",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the data for the Personal Loan Example in lecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83953724-582b-40c2-ac10-111e557f0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = pd.read_csv(os.path.join('..','data','UniversalBank.csv'))\n",
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a815492-f4e7-457b-afbb-156bd5ca4581",
   "metadata": {},
   "source": [
    "**Create crosstab summaries of the `Securities Account`, `CD Account`, `CreditCard` variables.**\n",
    "\n",
    "\n",
    "We start by building contingency tables (crosstabs) between each binary predictor and the target (**Personal Loan**). This lets us see how informative each split might be.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53fad99-e25c-4ed1-be76-732f79508c4e",
   "metadata": {},
   "source": [
    "**Run the next 3 cells**\n",
    "\n",
    "This is the code used to create the tables for the calculations for the first split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d93ee9-b860-4a84-be78-d2f9b5840080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['Securities Account'], bank_df['Personal Loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b80880d-2d9f-45c7-bc1b-83bc96e3925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['CD Account'], bank_df['Personal Loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b55823-e749-4dbc-8fcd-1eca8f5ba404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(bank_df['CreditCard'], bank_df['Personal Loan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc5ccf-4229-4597-b4f1-6e52b1e2b89f",
   "metadata": {},
   "source": [
    "**Calculate overall impurity for `Securities Account`, `CD Account`, `CreditCard` variables.**\n",
    "\n",
    "Now we try a **candidate split** for each of the 3 binary variables. We separate the data into the left/right child nodes and compute impurity for each side.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4126379-a413-47e6-8a96-ec860b16b28c",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This calculates the combined impurity for each of the 3 variables to evaluate which variable to use for the first split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11028a6d-edf8-403e-8016-5785084b87ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = ['Securities Account', 'CD Account', 'CreditCard']\n",
    "for var in vs:\n",
    "    split_condition = bank_df[var] == 0\n",
    "\n",
    "    split_true = list(bank_df['Personal Loan'][split_condition])\n",
    "    split_false = list(bank_df['Personal Loan'][~split_condition])\n",
    "\n",
    "    sa = weighted_impurity(split_true, split_false, bank_df[var], 'gini')\n",
    "    print(f\"Combined Gini for {var} Split is {sa:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088d4ee-d053-4619-afcd-b14f50c86222",
   "metadata": {},
   "source": [
    "**Create Decision Tree with a Depth of 2 with only the Securities Account, CD Account, CreditCard variables.**\n",
    "\n",
    "Use Gini for splitting criteria and display impurity value on nodes.\n",
    "\n",
    "\n",
    "Next, we fit a small decision tree with **max_depth=2** (a shallow, interpretable tree) using **Gini** as the split criterion, then visualize it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331253b-423a-452c-b40b-a89dd59ca379",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This is the code used to create the final tree for the Personal Loan Example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7cf12-ab2a-46a1-b088-2e429fb21da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_X = bank_df[vs]\n",
    "bank_y = bank_df['Personal Loan']\n",
    "dt3 = DecisionTreeClassifier(max_depth=2, criterion='gini', random_state=SEED)\n",
    "dt3.fit(bank_X, bank_y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plot_tree(dt3, \n",
    "          feature_names=bank_X.columns, \n",
    "          class_names=['Declined', 'Accepted'], \n",
    "          filled=True, \n",
    "          impurity=True, \n",
    "          ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70354ca0-67a9-47cd-bf51-7602394f727c",
   "metadata": {},
   "source": [
    "## Create a Text Version of Tree\n",
    "\n",
    "The `export_text()` function converts the trained tree into a readable rule-based format.\n",
    "\n",
    "Instead of a visual diagram, this shows:\n",
    "\n",
    "* The sequence of splits\n",
    "* The decision rules\n",
    "* The predicted class at each leaf\n",
    "* (Optional) Sample counts / weights\n",
    "\n",
    "**Run the next cell**\n",
    "\n",
    "Typically in Jupyter Noteboook, you don't need to use the `print()` function but this is a good example where it preserves the formatting of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961fc12-35ba-4949-a34f-85cf1650a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(dt3, feature_names=bank_X.columns, show_weights=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d7d1f-821f-4118-9d54-6714451281cc",
   "metadata": {},
   "source": [
    "**Create a fully developed Decision Tree with all variables except for `ID` and `Zip Code`.**\n",
    "\n",
    "Use Gini for splitting criteria and use the text dmba `plotDecisionTree()` to display the tree.\n",
    "\n",
    "Finally, we build a fuller model using all available predictors (excluding identifier fields) and plot the resulting tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d19416-e39c-4708-993c-bbe93954a676",
   "metadata": {},
   "source": [
    "**Run the next cell**\n",
    "\n",
    "This example was not shown in the lecture but included as a method to effectively visualize a very complex tree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ff53d-eb8e-4681-9506-9c57e67d2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_X = bank_df.drop(columns=['ID', 'ZIP Code', 'Personal Loan'])\n",
    "bank_y = bank_df['Personal Loan']\n",
    "\n",
    "fullClassTree = DecisionTreeClassifier(random_state=SEED).fit(bank_X, bank_y)\n",
    "plotDecisionTree(fullClassTree, feature_names=bank_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65c4a6-c326-4f97-9bde-7c7609d20a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
